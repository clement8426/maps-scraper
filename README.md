# ğŸš€ Scraper Google Maps - Suisse Romande (Mode GuÃ©rilla)

Pipeline d'extraction et d'enrichissement de donnÃ©es d'entreprises tech en Suisse Romande **sans API payante**.

## âš ï¸ Avertissements Importants

**Ce script est fourni Ã  des fins Ã©ducatives et de recherche uniquement.**

- âš ï¸ **Respectez les conditions d'utilisation de Google Maps**
- âš ï¸ **Respectez le `robots.txt` des sites web visitÃ©s**
- âš ï¸ **Ne surchargez pas les serveurs** (dÃ©lais intÃ©grÃ©s)
- âš ï¸ **VÃ©rifiez la lÃ©galitÃ©** de l'utilisation dans votre juridiction
- âš ï¸ **Les emails rÃ©cupÃ©rÃ©s** doivent respecter le RGPD et les lois anti-spam

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- Navigateur Chromium (installÃ© via Playwright)

## ğŸ› ï¸ Installation

```bash
# Installer les dÃ©pendances Python
pip install -r requirements.txt

# Installer les navigateurs Playwright (Firefox recommandÃ©)
playwright install firefox
# OU pour Chromium
playwright install chromium

# Tester que Playwright fonctionne
python test_playwright.py

# Tester avec Google Maps (Firefox recommandÃ©)
python test_firefox.py
```

**âš ï¸ Note importante :**
- **Firefox est recommandÃ©** car il semble mieux fonctionner avec Google Maps
- Le script utilise Firefox par dÃ©faut (configurable dans `scraper_suisse_romande.py`)
- Google Maps peut rediriger vers une page de consentement - le script la gÃ¨re automatiquement

## ğŸ¯ Architecture

Le systÃ¨me se compose de 3 phases :

1. **Harvester (Moissonneur)** : Parcourt Google Maps par secteurs gÃ©ographiques
2. **Enricher (Enrichisseur)** : RÃ©cupÃ¨re les sites web depuis les fiches Maps
3. **Miner (Mineur)** : Visite les sites web pour extraire emails et liens sociaux

## ğŸš€ Utilisation

### Ã‰tape 1 : Lancer le scraper principal

```bash
python scraper_suisse_romande.py
```

**FonctionnalitÃ©s :**
- âœ… Sauvegarde incrÃ©mentale (peut Ãªtre interrompu et relancÃ©)
- âœ… Gestion des sites React/SPA avec Playwright
- âœ… DÃ©lais alÃ©atoires pour simuler un comportement humain
- âœ… Rotation des User-Agents
- âœ… Gestion des erreurs et timeouts

**Fichiers gÃ©nÃ©rÃ©s :**
- `base_tech_suisse.csv` : RÃ©sultat final
- `intermediate_data.csv` : Sauvegarde intermÃ©diaire (supprimÃ© Ã  la fin)
- `checkpoint.json` : Checkpoint pour reprendre (supprimÃ© Ã  la fin)

### Ã‰tape 2 : VÃ©rifier les emails (Optionnel mais recommandÃ©)

Avant d'envoyer des emails marketing, vÃ©rifiez que les domaines sont valides :

```bash
python verify_emails.py base_tech_suisse.csv
```

Cela ajoute une colonne `Email_Valid` au CSV.

### Ã‰tape 3 : Nettoyer et enrichir les donnÃ©es

```bash
python clean_and_deduce_emails.py base_tech_suisse.csv
```

**FonctionnalitÃ©s :**
- Nettoie les URLs et extrait les domaines
- Identifie les emails gÃ©nÃ©riques (info@, contact@, etc.)
- DÃ©duit des emails possibles Ã  partir des noms d'entreprises
- Filtre les lignes incomplÃ¨tes

## ğŸ“Š Structure des DonnÃ©es

Le CSV final contient :

| Colonne | Description |
|---------|-------------|
| `Company` | Nom de l'entreprise |
| `Maps_Link` | Lien vers la fiche Google Maps |
| `City` | Ville |
| `Tag` | Mot-clÃ© de recherche utilisÃ© |
| `Website` | Site web de l'entreprise |
| `Email` | Emails trouvÃ©s (peut Ãªtre multiple, sÃ©parÃ©s par virgule) |
| `Social_Links` | Liens vers rÃ©seaux sociaux |
| `Status` | Statut du scraping |

## âš™ï¸ Configuration

Modifiez les constantes dans `scraper_suisse_romande.py` :

```python
CITIES = ["GenÃ¨ve", "Lausanne", ...]  # Villes Ã  scraper
KEYWORDS = ["Agence Web", ...]         # Mots-clÃ©s de recherche
MIN_DELAY = 1.5                        # DÃ©lai minimum entre actions
MAX_DELAY = 4.0                        # DÃ©lai maximum entre actions
```

## ğŸ›¡ï¸ Protection Anti-Ban

Le script inclut plusieurs mÃ©canismes pour Ã©viter les blocages :

- âœ… DÃ©lais alÃ©atoires entre chaque action
- âœ… Rotation des User-Agents
- âœ… Simulation d'un comportement humain (scroll, pauses)
- âœ… Gestion des cookies Google
- âœ… Timeouts adaptatifs

**Si vous Ãªtes bloquÃ© :**
- Augmentez les dÃ©lais (`MIN_DELAY`, `MAX_DELAY`)
- Utilisez un VPN ou changez d'IP
- RÃ©duisez le nombre de villes/mots-clÃ©s par session

## ğŸ› DÃ©pannage

### Le navigateur plante (SEGV_MAPERR, segmentation fault)

- ProblÃ¨me connu avec certaines versions de Playwright/Chromium sur macOS
- **Solutions** :
  1. Le script utilise Firefox par dÃ©faut maintenant (meilleure compatibilitÃ©)
  2. Le script utilise `headless=True` par dÃ©faut (Ã©vite les problÃ¨mes d'affichage)
  3. Si vous voulez utiliser Chromium : modifiez `BROWSER_TYPE = "chromium"` dans le script
  4. RÃ©installez Playwright si nÃ©cessaire : `playwright install firefox --force`

### Page de consentement Google

- Google Maps peut rediriger vers `consent.google.com`
- **Solution** : Le script gÃ¨re automatiquement cette page en acceptant les cookies/conditions
- Si le problÃ¨me persiste, essayez de visiter Google Maps manuellement dans un navigateur pour accepter les conditions une fois

### Le script plante aprÃ¨s quelques rÃ©sultats

- Google a peut-Ãªtre dÃ©tectÃ© le bot
- **Solution** : Augmentez les dÃ©lais (`MIN_DELAY`, `MAX_DELAY`), rÃ©duisez le nombre de recherches par session

### Pas d'emails trouvÃ©s sur les sites

- Certains sites sont en React/Vue.js et nÃ©cessitent JavaScript
- **Solution** : Le script utilise dÃ©jÃ  Playwright pour gÃ©rer cela, mais certains sites peuvent avoir des protections anti-bot

### Erreur "Timeout" frÃ©quente

- Connexion lente ou site bloquant
- **Solution** : Augmentez les timeouts dans le code ou vÃ©rifiez votre connexion

### Erreur "Target page, context or browser has been closed"

- Le navigateur a plantÃ© ou a Ã©tÃ© fermÃ©
- **Solution** : Le script sauvegarde automatiquement les donnÃ©es rÃ©cupÃ©rÃ©es. Relancez-le, il reprendra oÃ¹ il s'est arrÃªtÃ© grÃ¢ce aux checkpoints

## ğŸ“ Notes Importantes

1. **Emails gÃ©nÃ©riques** : La plupart des emails trouvÃ©s seront gÃ©nÃ©riques (`info@`, `contact@`). Pour des emails personnels, il faudra :
   - Rechercher manuellement sur LinkedIn
   - Utiliser des outils de dÃ©duction d'email (comme le script `clean_and_deduce_emails.py`)

2. **Faux positifs** : Certains rÃ©sultats peuvent ne pas Ãªtre des entreprises tech (ex: boutiques de rÃ©paration). Un tri manuel peut Ãªtre nÃ©cessaire.

3. **Limites Google Maps** : Google Maps limite Ã  ~120 rÃ©sultats par recherche. Le script utilise le scroll infini pour maximiser les rÃ©sultats.

## ğŸ”’ SÃ©curitÃ© et ConformitÃ©

- âœ… VÃ©rifiez toujours les emails avec `verify_emails.py` avant envoi
- âœ… Respectez le RGPD pour les emails marketing
- âœ… Utilisez un service d'email transactionnel avec bonne rÃ©putation
- âœ… Ne spammez pas : limitez le nombre d'emails par jour

## ğŸ“„ Licence

Ce code est fourni "tel quel" sans garantie. Utilisez-le Ã  vos propres risques.

## ğŸ¤ Contribution

AmÃ©liorations suggÃ©rÃ©es :
- Gestion des CAPTCHAs
- Support de proxies rotatifs
- Export vers d'autres formats (JSON, SQLite)
- Interface web pour monitoring

# maps-scraper
