# ğŸ•·ï¸ Scraper Google Maps - Suisse Romande

**SystÃ¨me complet de scraping avec interface web** pour extraire et gÃ©rer les donnÃ©es d'entreprises tech depuis Google Maps.

## âœ¨ CaractÃ©ristiques principales

### ğŸ¯ Scraping automatisÃ©
- **25 villes** (focus canton de NeuchÃ¢tel + Suisse Romande)
- **40 mots-clÃ©s tech** (Web, Software, SaaS, DevOps, Data, etc.)
- **1000 combinaisons possibles**
- Extraction : nom, adresse, tÃ©lÃ©phone, site web, email, note, avis

### ğŸŒ Interface web moderne
- **Dashboard en temps rÃ©el**
- **Filtres avancÃ©s** (ville, site web, email)
- **ContrÃ´le du scraper** (dÃ©marrage/arrÃªt)
- **Export CSV** avec filtres
- **Statistiques visuelles**

### ğŸ”’ SÃ©curitÃ©
- **Double authentification** (Nginx + Flask)
- **Firewall configurÃ©**
- **Mots de passe chiffrÃ©s**
- **HTTPS ready**

### ğŸ’¾ Stockage
- **SQLite** (base de donnÃ©es embarquÃ©e)
- **CSV** (export facile)
- **Sauvegarde automatique** (reprise aprÃ¨s interruption)

### ğŸ›¡ï¸ Anti-dÃ©tection
- **11 User-Agents rotatifs**
- **DÃ©lais alÃ©atoires**
- **Navigation naturelle**
- **Firefox headless**

### âœ… Validation intelligente
- **Emails vÃ©rifiÃ©s par DNS** (MX records)
- **Suppression des emails fictifs**
- **Nettoyage automatique**

## ğŸš€ Installation

### DÃ©veloppement local

```bash
# Cloner le repo
git clone https://github.com/VOTRE_USERNAME/maps-scrap.git
cd maps-scrap

# Installer les dÃ©pendances
pip install -r requirements.txt
playwright install firefox

# Copier l'exemple de configuration
cp env.example .env

# Modifier .env avec vos identifiants
nano .env

# Lancer le serveur
cd backend && python app.py
```

AccÃ©dez Ã  http://localhost:5000

### DÃ©ploiement VPS (Production)

```bash
# Sur le VPS (Ubuntu/Debian)
git clone https://github.com/VOTRE_USERNAME/maps-scrap.git
cd maps-scrap
sudo ./scripts/install.sh
```

**C'est tout !** Le script configure automatiquement :
- Python, Nginx, Playwright
- Service systemd
- Firewall
- Certificats

Voir [DEPLOY.md](DEPLOY.md) pour plus de dÃ©tails.

## ğŸ“ Structure du projet

```
maps-scrap/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                      # API Flask
â”‚   â”œâ”€â”€ scraper_suisse_romande.py   # Scraper principal
â”‚   â”œâ”€â”€ companies.db                # Base SQLite
â”‚   â””â”€â”€ checkpoint.json             # Progression
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                  # Dashboard
â”‚   â”œâ”€â”€ style.css                   # Styles
â”‚   â””â”€â”€ script.js                   # JavaScript
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ install.sh                  # Installation VPS
â”‚   â””â”€â”€ start.sh                    # DÃ©marrage manuel
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â”œâ”€â”€ README.md                       # Guide utilisateur
â””â”€â”€ DEPLOY.md                       # Guide dÃ©ploiement
```

## ğŸ® Utilisation

### Via l'interface web

1. **Ouvrir** l'interface : http://VOTRE_IP
2. **S'authentifier** avec vos identifiants
3. **DÃ©marrer le scraper** : cliquer sur "â–¶ï¸ DÃ©marrer"
4. **Filtrer** les rÃ©sultats par ville, email, site web
5. **Exporter** en CSV

### Via ligne de commande

```bash
# Lancer le scraper en CLI
cd backend
python scraper_suisse_romande.py

# RequÃªtes SQL directes
sqlite3 companies.db
SELECT * FROM companies WHERE city = 'NeuchÃ¢tel' AND email IS NOT NULL;
```

## ğŸ“Š API Endpoints

```
GET  /                          # Dashboard
GET  /api/companies             # Liste des entreprises (+ filtres)
GET  /api/stats                 # Statistiques
GET  /api/cities                # Liste des villes
GET  /api/scraper/status        # Statut du scraper
POST /api/scraper/start         # DÃ©marrer le scraper
POST /api/scraper/stop          # ArrÃªter le scraper
GET  /api/export/csv            # Exporter en CSV
```

## âš™ï¸ Configuration

### Variables d'environnement (.env)

```bash
WEB_USERNAME=admin              # Nom d'utilisateur web
WEB_PASSWORD=votre_mdp          # Mot de passe web
PORT=5000                       # Port du serveur
DEBUG=False                     # Mode debug
```

### Personnaliser les recherches

Modifier `backend/scraper_suisse_romande.py` :

```python
# Ajouter des villes
CITIES = [
    "NeuchÃ¢tel", "Le Locle", "La Chaux-de-Fonds",
    # Ajoutez vos villes ici
]

# Ajouter des mots-clÃ©s
KEYWORDS = [
    "Agence Web", "DÃ©veloppement logiciel",
    # Ajoutez vos keywords ici
]
```

## ğŸ”§ Maintenance

### Logs

```bash
# Logs du service
sudo journalctl -u scraper-web -f

# Logs Nginx
sudo tail -f /var/log/nginx/error.log
```

### Backup

```bash
# Sauvegarder la base de donnÃ©es
cp backend/companies.db ~/backup_$(date +%Y%m%d).db

# Restaurer
cp ~/backup_YYYYMMDD.db backend/companies.db
```

### Mise Ã  jour

```bash
git pull
sudo systemctl restart scraper-web
```

## ğŸ› DÃ©pannage

Voir [DEPLOY.md - Section DÃ©pannage](DEPLOY.md#-dÃ©pannage)

## ğŸ“ˆ Performance

- **Vitesse** : ~10-50 entreprises par recherche
- **DurÃ©e** : 8-12h pour toutes les combinaisons
- **Volume** : 10 000 - 50 000 entreprises potentielles

## âš ï¸ Avertissements lÃ©gaux

- **Usage personnel/Ã©ducatif uniquement**
- Respectez les CGU de Google Maps
- Respectez le RGPD et la LPD suisse
- Ne pas utiliser Ã  des fins commerciales sans autorisation
- DonnÃ©es publiques uniquement

## ğŸ¤ Contribution

Pour contribuer :
1. Fork le projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Commit (`git commit -m 'Ajout fonctionnalitÃ©'`)
4. Push (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

## ğŸ“ Licence

Ce projet est fourni Ã  des fins Ã©ducatives. Utilisez-le de maniÃ¨re responsable.

## ğŸ†˜ Support

- ğŸ“– Documentation : README.md + DEPLOY.md
- ğŸ› Issues : GitHub Issues
- ğŸ’¬ Questions : CrÃ©er une discussion

---

**Fait avec â¤ï¸ pour le canton de NeuchÃ¢tel et la Suisse Romande**

